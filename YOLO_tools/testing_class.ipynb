{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.class_yolo_trainer import YOLOTrainer\n",
    "\n",
    "yolo_trainer = YOLOTrainer\n",
    "yolo_trainer = YOLOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "We should have x_min < x_max and y_min < y_max. But we got (x_min = 0, y_min = 0, x_max = 597, y_max = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m yolo_trainer\u001b[38;5;241m.\u001b[39modd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m\n\u001b[0;32m     12\u001b[0m yolo_trainer\u001b[38;5;241m.\u001b[39mtest_percentual_divisor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[43myolo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslicing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\source\\class_yolo_trainer.py:19\u001b[0m, in \u001b[0;36mYOLOTrainer.slicing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslicing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mslicing_dataset_for_traning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotations_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myolo_Classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_percentual_divisor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\source\\modules\\slicing_dataset.py:24\u001b[0m, in \u001b[0;36mslicing_dataset_for_traning\u001b[1;34m(task, imageFolder, annotationsFolder, yoloClasses, TestPercentualDivisor, dataset_path, aug, n_aug, odd)\u001b[0m\n\u001b[0;32m     21\u001b[0m     detect_COCO_dataset(imageFolder, annotationsFolder, yoloClasses, TestPercentualDivisor, dataset_path)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aug:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43maug_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43modd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\source\\modules\\augmentations.py:19\u001b[0m, in \u001b[0;36maug_dataset\u001b[1;34m(task, dataset_path, n_aug, odd)\u001b[0m\n\u001b[0;32m     16\u001b[0m     aug_YOLO_classify(dataset_path, n_aug, odd)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOCO\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43maug_COCO_detect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43modd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\source\\modules\\augmentations.py:136\u001b[0m, in \u001b[0;36maug_COCO_detect\u001b[1;34m(dataset_path, n_aug, odd)\u001b[0m\n\u001b[0;32m    133\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(coco_data, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Processar os dois arquivos de anotações\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m \u001b[43mprocess_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_annotations_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m process_annotations(val_annotations_file, images_dir)\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\source\\modules\\augmentations.py:91\u001b[0m, in \u001b[0;36maug_COCO_detect.<locals>.process_annotations\u001b[1;34m(annotations_file, images_dir)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(n_aug)):\n\u001b[1;32m---> 91\u001b[0m     augmented \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     transformed_image \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     94\u001b[0m     transformed_bboxes \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\yolo-trainer-venv\\Lib\\site-packages\\albumentations\\core\\composition.py:441\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m--> 441\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_transform_params(t, data)\n\u001b[0;32m    443\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_data_post_transform(data)\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\yolo-trainer-venv\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:173\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[1;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic:\n\u001b[0;32m    172\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\yolo-trainer-venv\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:198\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key2func \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key2func[key]\n\u001b[0;32m    197\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m ensure_contiguous_output(\n\u001b[1;32m--> 198\u001b[0m         \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_contiguous_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m arg\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\yolo-trainer-venv\\Lib\\site-packages\\albumentations\\augmentations\\crops\\transforms.py:71\u001b[0m, in \u001b[0;36mBaseCrop.apply\u001b[1;34m(self, img, crop_coords, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     67\u001b[0m     img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     68\u001b[0m     crop_coords: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any,\n\u001b[0;32m     70\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfcrops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Judson_projetos\\Yolo_trainer\\YOLO_tools\\yolo-trainer-venv\\Lib\\site-packages\\albumentations\\augmentations\\crops\\functional.py:142\u001b[0m, in \u001b[0;36mcrop\u001b[1;34m(img, x_min, y_min, x_max, y_max)\u001b[0m\n\u001b[0;32m    140\u001b[0m height, width \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_max \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m x_min \u001b[38;5;129;01mor\u001b[39;00m y_max \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m y_min:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe should have x_min < x_max and y_min < y_max. But we got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (x_min = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_min = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x_max = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_max = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m     )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x_max \u001b[38;5;241m>\u001b[39m width \u001b[38;5;129;01mor\u001b[39;00m y_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y_max \u001b[38;5;241m>\u001b[39m height:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValues for crop should be non negative and equal or smaller than image sizes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(x_min = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_min = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x_max = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_max = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, width = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: We should have x_min < x_max and y_min < y_max. But we got (x_min = 0, y_min = 0, x_max = 597, y_max = 0)"
     ]
    }
   ],
   "source": [
    "### vou deixar anotado porque não sei se fiz gambiarra, \n",
    "\"\"\" no atributo image_folder para tarefas de classificação eu estou passando somente a pasta do dataset, sem indicar a pasta de imagens\n",
    "\"\"\"\n",
    "yolo_trainer.image_folder = r\"emissoes_dataset_COCO\\images\"\n",
    "yolo_trainer.annotations_folder = r\"emissoes_dataset_COCO\\annotations\"\n",
    "yolo_trainer.yolo_Classes = [\"emissao\"]\n",
    "yolo_trainer.dataset_path = \"emissoes_COCO\"\n",
    "yolo_trainer.task = \"COCO\"\n",
    "yolo_trainer.aug = True\n",
    "yolo_trainer.n_aug = 10\n",
    "yolo_trainer.odd = 0.15\n",
    "yolo_trainer.test_percentual_divisor = 20\n",
    "\n",
    "yolo_trainer.slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "#### YOLO é gambiarra e eu posso provar:\n",
    "\"\"\" Para treinamentos de classificação com YOLO, você deve indicar o dir com o dataset\n",
    "que deve estar especificado dentro de uma pasta chamada 'datasets'. No entando, para detecção\n",
    "o YOLO é diferente. Você precisa indicar o caminho do arquivo 'dataset.yaml' para que ele \n",
    "possa encontrar o dataset e realizar o treinamento. É a mesma função, de uma mesma lib,\n",
    "mas os caras fizeram de forma que o mesmo argumento recebe duas entradas completamente \n",
    "diferentes a depender do treinamento que você vai fazer.\n",
    "\"\"\"\n",
    "\n",
    "# Carregar configurações de um arquivo YAML\n",
    "with open('../hyper_yolo.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "train_config = config['train']\n",
    "aug_config = config['train']['augmentation']\n",
    "\n",
    "model = YOLO(\"runs\\\\detect\\\\train52\\\\weights\\\\best.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data = \"datasets/emissoes_YOLO/dataset.yaml\",\n",
    "    device = \"cuda\",\n",
    "\n",
    "    ### training configs. Checkout hyper_yolo.yaml for details\n",
    "    imgsz = train_config['imgsz'],\n",
    "    batch = train_config['batch'],\n",
    "    weight_decay = train_config['weight_decay'],\n",
    "\n",
    "    warmup_epochs = train_config['warmup_epochs'],\n",
    "    warmup_momentum = train_config['warmup_momentum'],\n",
    "    warmup_bias_lr = train_config['warmup_bias_lr'],\n",
    "\n",
    "    epochs = train_config['epochs'],\n",
    "    momentum = train_config['momentum'],\n",
    "    lr0 = train_config['lr0'],\n",
    "    lrf = train_config['lrf'],\n",
    "    optimizer = train_config['optimizer'],\n",
    "\n",
    "    ### if you r willing to use yolo aug, uncomment section bellow\n",
    "    ### not recomended if ur data is already aug though\n",
    "    ### augment args\n",
    "    # hsv_h = aug_config['hsv_h'],\n",
    "    # hsv_s = aug_config['hsv_s'],\n",
    "    # hsv_v = aug_config['hsv_v'],\n",
    "    # degrees = aug_config['degrees'],\n",
    "    # translate = aug_config['translate'],\n",
    "    # scale = aug_config['scale'],\n",
    "    # shear = aug_config['shear'],\n",
    "    # perspective = aug_config['perspective'],\n",
    "    # flipud = aug_config['flipud'],\n",
    "    # fliplr = aug_config['fliplr'],\n",
    "    # mosaic = aug_config['mosaic'],\n",
    "    # mixup = aug_config['mixup'],\n",
    "    # copy_paste = aug_config['copy_paste'],\n",
    "    # auto_augment = aug_config['auto_augment'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs\\\\detect\\\\train52\\\\weights\\\\best.pt\")\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "train = 'train52'\n",
    "model = YOLO(f\"runs/detect/{train}/weights/best.pt\")\n",
    "model.predict(\"../RUIM 23-06-22 (1).mp4\", save=True, conf=0.4, device=\"cuda\", save_txt=False, save_conf=True, save_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.check_file import check_file\n",
    "\n",
    "check_file(\"datasets\\\\emissoes_YOLO\\\\dataset.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch_is_available import torch_is_available\n",
    "\n",
    "torch_is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cvat_dataset import cvat_dataset\n",
    "\n",
    "cvat_dataset(\"../emissoes_dataset_CVAT\", \"emissoes_dataset_YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.remover_labels_vazios import processar_dataset\n",
    "\n",
    "processar_dataset(\"emissoes_dataset_YOLO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-for-training-UuJD_CB9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
